{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alecr\\Anaconda3\\envs\\gensim_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (20,23,28,29,30,31,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\data\\openparliament\\statements_nospeaker_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>politician_id</th>\n",
       "      <th>riding_id</th>\n",
       "      <th>party_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>start_date</th>\n",
       "      <th>id.1</th>\n",
       "      <th>document_id</th>\n",
       "      <th>time</th>\n",
       "      <th>h1_en</th>\n",
       "      <th>...</th>\n",
       "      <th>slug</th>\n",
       "      <th>urlcache</th>\n",
       "      <th>h1_fr</th>\n",
       "      <th>h2_fr</th>\n",
       "      <th>h3_fr</th>\n",
       "      <th>who_fr</th>\n",
       "      <th>who_context_fr</th>\n",
       "      <th>wordcount_en</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>slug_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2611</td>\n",
       "      <td>3465</td>\n",
       "      <td>35066</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-11-29</td>\n",
       "      <td>1997-09-22</td>\n",
       "      <td>232373</td>\n",
       "      <td>1878</td>\n",
       "      <td>2001-05-03 13:50:00-04</td>\n",
       "      <td>Government Orders</td>\n",
       "      <td>...</td>\n",
       "      <td>marlene-catterall-1</td>\n",
       "      <td>/debates/2001/5/3/marlene-catterall-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3210</td>\n",
       "      <td>3465</td>\n",
       "      <td>70224</td>\n",
       "      <td>4</td>\n",
       "      <td>1997-04-27</td>\n",
       "      <td>1994-01-17</td>\n",
       "      <td>232373</td>\n",
       "      <td>1878</td>\n",
       "      <td>2001-05-03 13:50:00-04</td>\n",
       "      <td>Government Orders</td>\n",
       "      <td>...</td>\n",
       "      <td>marlene-catterall-1</td>\n",
       "      <td>/debates/2001/5/3/marlene-catterall-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4305</td>\n",
       "      <td>173</td>\n",
       "      <td>70358</td>\n",
       "      <td>1</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>645329</td>\n",
       "      <td>388</td>\n",
       "      <td>2008-02-14 13:15:00-05</td>\n",
       "      <td>Routine Proceedings</td>\n",
       "      <td>...</td>\n",
       "      <td>tom-lukiwski-7</td>\n",
       "      <td>/debates/2008/2/14/tom-lukiwski-7/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['finally', ',', 'mr.', 'speaker', ',', 'i', '...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1534</td>\n",
       "      <td>173</td>\n",
       "      <td>47007</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>2004-10-04</td>\n",
       "      <td>645329</td>\n",
       "      <td>388</td>\n",
       "      <td>2008-02-14 13:15:00-05</td>\n",
       "      <td>Routine Proceedings</td>\n",
       "      <td>...</td>\n",
       "      <td>tom-lukiwski-7</td>\n",
       "      <td>/debates/2008/2/14/tom-lukiwski-7/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['finally', ',', 'mr.', 'speaker', ',', 'i', '...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1541</td>\n",
       "      <td>43</td>\n",
       "      <td>47014</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>2004-10-04</td>\n",
       "      <td>313253</td>\n",
       "      <td>1621</td>\n",
       "      <td>2004-02-06 10:05:00-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>garry-breitkreuz-1</td>\n",
       "      <td>/debates/2004/2/6/garry-breitkreuz-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'today', ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  politician_id  riding_id  party_id    end_date  start_date    id.1  \\\n",
       "0  2611           3465      35066         4  2005-11-29  1997-09-22  232373   \n",
       "1  3210           3465      70224         4  1997-04-27  1994-01-17  232373   \n",
       "2  4305            173      70358         1          \\N  2015-10-19  645329   \n",
       "3  1534            173      47007         1  2015-10-19  2004-10-04  645329   \n",
       "4  1541             43      47014         1  2015-10-19  2004-10-04  313253   \n",
       "\n",
       "   document_id                    time                h1_en  ...  \\\n",
       "0         1878  2001-05-03 13:50:00-04    Government Orders  ...   \n",
       "1         1878  2001-05-03 13:50:00-04    Government Orders  ...   \n",
       "2          388  2008-02-14 13:15:00-05  Routine Proceedings  ...   \n",
       "3          388  2008-02-14 13:15:00-05  Routine Proceedings  ...   \n",
       "4         1621  2004-02-06 10:05:00-05                  NaN  ...   \n",
       "\n",
       "                  slug                                urlcache h1_fr h2_fr  \\\n",
       "0  marlene-catterall-1  /debates/2001/5/3/marlene-catterall-1/   NaN   NaN   \n",
       "1  marlene-catterall-1  /debates/2001/5/3/marlene-catterall-1/   NaN   NaN   \n",
       "2       tom-lukiwski-7      /debates/2008/2/14/tom-lukiwski-7/   NaN   NaN   \n",
       "3       tom-lukiwski-7      /debates/2008/2/14/tom-lukiwski-7/   NaN   NaN   \n",
       "4   garry-breitkreuz-1   /debates/2004/2/6/garry-breitkreuz-1/   NaN   NaN   \n",
       "\n",
       "   h3_fr  who_fr  who_context_fr wordcount_en  \\\n",
       "0    NaN     NaN             NaN           \\N   \n",
       "1    NaN     NaN             NaN           \\N   \n",
       "2    NaN     NaN             NaN           \\N   \n",
       "3    NaN     NaN             NaN           \\N   \n",
       "4    NaN     NaN             NaN           \\N   \n",
       "\n",
       "                                   tokenized_content slug_length  \n",
       "0  ['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...           3  \n",
       "1  ['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...           3  \n",
       "2  ['finally', ',', 'mr.', 'speaker', ',', 'i', '...           3  \n",
       "3  ['finally', ',', 'mr.', 'speaker', ',', 'i', '...           3  \n",
       "4  ['mr.', 'speaker', ',', 'i', 'rise', 'today', ...           3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '!\"#$%&()*+,-./:;<=>@[]^_`{|}~' + \"''\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pun_trans = str.maketrans(dict.fromkeys(punctuation, ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_chunk = pd.read_csv(r\"D:\\data\\openparliament\\statements_nospeaker_en.csv\", chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_en_list = []  # append the content from each chunk df here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_column (row):\n",
    "    soup = BeautifulSoup(row)\n",
    "    text = soup.text.lower()\n",
    "    text = text.translate(pun_trans)\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    text = text.replace('â€”', ' ')\n",
    "    words = word_tokenize(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word_tokens):\n",
    "    tokens = [w for w in word_tokens if not w in stop_words]\n",
    "    tokens = [t for t in tokens if not t.isdigit()]\n",
    "    words = [ps.stem(w) for w in tokens]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Each chunk is in df format\n",
    "count = 0\n",
    "for chunk in df_chunk:  \n",
    "    # perform data filtering \n",
    "    print('chunk count', count)\n",
    "    count+=1\n",
    "    chunk_filter = chunk.drop(['Unnamed: 0'], axis=1)\n",
    "    content_en = chunk.content_en\n",
    "    #print(type(content_en))\n",
    "    content_en = content_en.apply(tokenize_column)\n",
    "    content_en = content_en.apply(remove_stopwords)\n",
    "    chunk_filter['tokens'] = content_en\n",
    "    #print(type(chunk_filter))\n",
    "    #print('done')\n",
    "    # Once the data filtering is done, append the chunk to list\n",
    "    content_en_list.append(chunk_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'politician_id', 'riding_id', 'party_id', 'end_date',\n",
       "       'start_date', 'id.1', 'document_id', 'time', 'h1_en', 'h2_en',\n",
       "       'member_id', 'who_en', 'content_en', 'sequence_en', 'wordcount',\n",
       "       'politician_id.1', 'procedural', 'h3_en', 'who_hocid', 'content_fr',\n",
       "       'statement_type', 'written_question', 'source_id', 'who_context_en',\n",
       "       'slug', 'urlcache', 'h1_fr', 'h2_fr', 'h3_fr', 'who_fr',\n",
       "       'who_context_fr', 'wordcount_en', 'tokenized_content', 'slug_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\site-packages\\bs4\\builder\\_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m             \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# < + letter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"</\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDATA_CONTENT_ELEMENTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cdata_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\site-packages\\bs4\\builder\\_htmlparser.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[1;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[0;32m    151\u001b[0m         tag = self.soup.handle_starttag(\n\u001b[0;32m    152\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msourceline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msourceline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0msourcepos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msourcepos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_empty_element\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhandle_empty_element\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos)\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentTag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m             \u001b[0msourceline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msourceline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msourcepos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msourcepos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m         )\n\u001b[0;32m    708\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gensim_env\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml, sourceline, sourcepos, can_be_empty_element, cdata_list_attributes, preserve_whitespace_tags)\u001b[0m\n\u001b[0;32m   1106\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No value provided for new tag's name.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamespace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m         if ((not builder or builder.store_line_numbers)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_tokens = 0\n",
    "count = 0\n",
    "\n",
    "for index, row in df.iterrows(): \n",
    "    if count%10000==0:\n",
    "        print(count)\n",
    "    soup = BeautifulSoup(row.content_en)\n",
    "    text = soup.text.lower()\n",
    "    text = text.translate(pun_trans)\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    text = text.replace('â€”', ' ')\n",
    "    word_tokens = word_tokenize(text)\n",
    "    tokens = [w for w in word_tokens if not w in stop_words]\n",
    "    tokens = [t for t in tokens if not t.isdigit()]\n",
    "    words = [ps.stem(w) for w in tokens]\n",
    "    if len(words)>max_tokens:\n",
    "        max_tokens = len(words)\n",
    "    count+=1\n",
    "print(row.who_en, \"gave the longest speech at\", max_tokens, 'words')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = content_en_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(content_en_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_concat = pd.concat(content_en_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politician_id = list(set(df_concat.politician_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[4] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_concat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = list(set(df_concat.politician_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(politicians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict = vocab_count_dict.fromkeys(politicians, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "counter = 0\n",
    "for index, row in df_concat.iterrows(): \n",
    "    if counter%100000 ==0:\n",
    "        print('at row', counter)\n",
    "        \n",
    "    pid = row['politician_id']\n",
    "    vocab_count_dict[pid].update(row['tokens'])\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict[4156]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: filter out '\\\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'court.\\\\nthen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\\\n' in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.split('\\\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab_count_dict[4156])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set = vocab_count_dict[4156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(p_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set.remove('sacrifice.\\\\ntoday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "for key, p_set in vocab_count_dict.items():\n",
    "    #iterate through items in p_set\n",
    "    v_set = list(p_set)\n",
    "    for val in p_set:\n",
    "        #remove punctuation, maybe with regex\n",
    "        new_vals = val.split('\\\\n')\n",
    "        #vocab_count_dict[key].remove(val)\n",
    "        #vocab_count_dict[key].update(new_vals) \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pun_trans = str.maketrans(dict.fromkeys(punctuation, ' '))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'ministers.\\\\nand'.translate(pun_trans)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tasks: add 'mr' to stopwords"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'â€”' == '-'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_concat.to_pickle(\"D:\\data\\openparliament\\content_en_vcount.pkl\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
