{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.read_csv(r\"D:\\data\\openparliament\\statements_nospeaker_en.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.drop('Unnamed: 0',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunk = pd.read_csv(r\"D:\\data\\openparliament\\statements_nospeaker_en.csv\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_en_list = []  # append the content from each chunk df here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "punctuation = '!\"#$%&\\'()*+,-./:;<=>@[\\\\]^_`{|}~'\n",
    "\n",
    "df_chunk = pd.read_csv(r\"D:\\data\\openparliament\\statements_nospeaker_en.csv\", chunksize=10000)\n",
    "\n",
    "content_en_list = []  # append the content from each chunk df here \n",
    "\n",
    "def tokenize_column (row):\n",
    "    soup = BeautifulSoup(row)\n",
    "    text = soup.text.lower()\n",
    "    words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(word_tokens):\n",
    "    words = [w for w in word_tokens if not w in stop_words]\n",
    "    words = [w for w in word_tokens if not w in punctuation]\n",
    "    return words\n",
    "\n",
    "\n",
    "# Each chunk is in df format\n",
    "for chunk in df_chunk:  \n",
    "    # perform data filtering \n",
    "    chunk_filter = chunk.drop(['Unnamed: 0'], axis=1)\n",
    "    content_en = chunk.content_en\n",
    "    print(type(content_en))\n",
    "    content_en = content_en.apply(tokenize_column)\n",
    "    content_en = content_en.apply(remove_stopwords)\n",
    "    chunk_filter['tokens'] = content_en\n",
    "    print(type(chunk_filter))\n",
    "    print('done')\n",
    "    # Once the data filtering is done, append the chunk to list\n",
    "    content_en_list.append(chunk_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_en_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 891 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_concat = pd.concat(content_en_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>politician_id</th>\n",
       "      <th>riding_id</th>\n",
       "      <th>party_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>start_date</th>\n",
       "      <th>id.1</th>\n",
       "      <th>document_id</th>\n",
       "      <th>time</th>\n",
       "      <th>h1_en</th>\n",
       "      <th>...</th>\n",
       "      <th>urlcache</th>\n",
       "      <th>h1_fr</th>\n",
       "      <th>h2_fr</th>\n",
       "      <th>h3_fr</th>\n",
       "      <th>who_fr</th>\n",
       "      <th>who_context_fr</th>\n",
       "      <th>wordcount_en</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>slug_length</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2611</td>\n",
       "      <td>3465</td>\n",
       "      <td>35066</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-11-29</td>\n",
       "      <td>1997-09-22</td>\n",
       "      <td>232373</td>\n",
       "      <td>1878</td>\n",
       "      <td>2001-05-03 13:50:00-04</td>\n",
       "      <td>Government Orders</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2001/5/3/marlene-catterall-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...</td>\n",
       "      <td>3</td>\n",
       "      <td>[mr., speaker, i, rise, on, a, point, of, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3210</td>\n",
       "      <td>3465</td>\n",
       "      <td>70224</td>\n",
       "      <td>4</td>\n",
       "      <td>1997-04-27</td>\n",
       "      <td>1994-01-17</td>\n",
       "      <td>232373</td>\n",
       "      <td>1878</td>\n",
       "      <td>2001-05-03 13:50:00-04</td>\n",
       "      <td>Government Orders</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2001/5/3/marlene-catterall-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...</td>\n",
       "      <td>3</td>\n",
       "      <td>[mr., speaker, i, rise, on, a, point, of, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4305</td>\n",
       "      <td>173</td>\n",
       "      <td>70358</td>\n",
       "      <td>1</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>645329</td>\n",
       "      <td>388</td>\n",
       "      <td>2008-02-14 13:15:00-05</td>\n",
       "      <td>Routine Proceedings</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2008/2/14/tom-lukiwski-7/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['finally', ',', 'mr.', 'speaker', ',', 'i', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>[finally, mr., speaker, i, ask, that, all, rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1534</td>\n",
       "      <td>173</td>\n",
       "      <td>47007</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>2004-10-04</td>\n",
       "      <td>645329</td>\n",
       "      <td>388</td>\n",
       "      <td>2008-02-14 13:15:00-05</td>\n",
       "      <td>Routine Proceedings</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2008/2/14/tom-lukiwski-7/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['finally', ',', 'mr.', 'speaker', ',', 'i', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>[finally, mr., speaker, i, ask, that, all, rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1541</td>\n",
       "      <td>43</td>\n",
       "      <td>47014</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>2004-10-04</td>\n",
       "      <td>313253</td>\n",
       "      <td>1621</td>\n",
       "      <td>2004-02-06 10:05:00-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2004/2/6/garry-breitkreuz-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'today', ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[mr., speaker, i, rise, today, on, a, question...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  politician_id  riding_id  party_id    end_date  start_date    id.1  \\\n",
       "0  2611           3465      35066         4  2005-11-29  1997-09-22  232373   \n",
       "1  3210           3465      70224         4  1997-04-27  1994-01-17  232373   \n",
       "2  4305            173      70358         1          \\N  2015-10-19  645329   \n",
       "3  1534            173      47007         1  2015-10-19  2004-10-04  645329   \n",
       "4  1541             43      47014         1  2015-10-19  2004-10-04  313253   \n",
       "\n",
       "   document_id                    time                h1_en  ...  \\\n",
       "0         1878  2001-05-03 13:50:00-04    Government Orders  ...   \n",
       "1         1878  2001-05-03 13:50:00-04    Government Orders  ...   \n",
       "2          388  2008-02-14 13:15:00-05  Routine Proceedings  ...   \n",
       "3          388  2008-02-14 13:15:00-05  Routine Proceedings  ...   \n",
       "4         1621  2004-02-06 10:05:00-05                  NaN  ...   \n",
       "\n",
       "                                 urlcache  h1_fr h2_fr h3_fr  who_fr  \\\n",
       "0  /debates/2001/5/3/marlene-catterall-1/    NaN   NaN   NaN     NaN   \n",
       "1  /debates/2001/5/3/marlene-catterall-1/    NaN   NaN   NaN     NaN   \n",
       "2      /debates/2008/2/14/tom-lukiwski-7/    NaN   NaN   NaN     NaN   \n",
       "3      /debates/2008/2/14/tom-lukiwski-7/    NaN   NaN   NaN     NaN   \n",
       "4   /debates/2004/2/6/garry-breitkreuz-1/    NaN   NaN   NaN     NaN   \n",
       "\n",
       "   who_context_fr  wordcount_en  \\\n",
       "0             NaN            \\N   \n",
       "1             NaN            \\N   \n",
       "2             NaN            \\N   \n",
       "3             NaN            \\N   \n",
       "4             NaN            \\N   \n",
       "\n",
       "                                   tokenized_content slug_length  \\\n",
       "0  ['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...           3   \n",
       "1  ['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...           3   \n",
       "2  ['finally', ',', 'mr.', 'speaker', ',', 'i', '...           3   \n",
       "3  ['finally', ',', 'mr.', 'speaker', ',', 'i', '...           3   \n",
       "4  ['mr.', 'speaker', ',', 'i', 'rise', 'today', ...           3   \n",
       "\n",
       "                                              tokens  \n",
       "0  [mr., speaker, i, rise, on, a, point, of, orde...  \n",
       "1  [mr., speaker, i, rise, on, a, point, of, orde...  \n",
       "2  [finally, mr., speaker, i, ask, that, all, rem...  \n",
       "3  [finally, mr., speaker, i, ask, that, all, rem...  \n",
       "4  [mr., speaker, i, rise, today, on, a, question...  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the english statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "politician_id = list(set(df_concat.politician_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'politician_id', 'riding_id', 'party_id', 'end_date',\n",
       "       'start_date', 'id.1', 'document_id', 'time', 'h1_en', 'h2_en',\n",
       "       'member_id', 'who_en', 'content_en', 'sequence_en', 'wordcount',\n",
       "       'politician_id.1', 'procedural', 'h3_en', 'who_hocid', 'content_fr',\n",
       "       'statement_type', 'written_question', 'source_id', 'who_context_en',\n",
       "       'slug', 'urlcache', 'h1_fr', 'h2_fr', 'h3_fr', 'who_fr',\n",
       "       'who_context_fr', 'wordcount_en', 'tokenized_content', 'slug_length',\n",
       "       'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[4] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100\n",
      "11 110\n",
      "12 120\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row['c1'], row['c2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_concat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>politician_id</th>\n",
       "      <th>riding_id</th>\n",
       "      <th>party_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>start_date</th>\n",
       "      <th>id.1</th>\n",
       "      <th>document_id</th>\n",
       "      <th>time</th>\n",
       "      <th>h1_en</th>\n",
       "      <th>...</th>\n",
       "      <th>urlcache</th>\n",
       "      <th>h1_fr</th>\n",
       "      <th>h2_fr</th>\n",
       "      <th>h3_fr</th>\n",
       "      <th>who_fr</th>\n",
       "      <th>who_context_fr</th>\n",
       "      <th>wordcount_en</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>slug_length</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2611</td>\n",
       "      <td>3465</td>\n",
       "      <td>35066</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-11-29</td>\n",
       "      <td>1997-09-22</td>\n",
       "      <td>232373</td>\n",
       "      <td>1878</td>\n",
       "      <td>2001-05-03 13:50:00-04</td>\n",
       "      <td>Government Orders</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2001/5/3/marlene-catterall-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...</td>\n",
       "      <td>3</td>\n",
       "      <td>[mr., speaker, i, rise, on, a, point, of, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3210</td>\n",
       "      <td>3465</td>\n",
       "      <td>70224</td>\n",
       "      <td>4</td>\n",
       "      <td>1997-04-27</td>\n",
       "      <td>1994-01-17</td>\n",
       "      <td>232373</td>\n",
       "      <td>1878</td>\n",
       "      <td>2001-05-03 13:50:00-04</td>\n",
       "      <td>Government Orders</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2001/5/3/marlene-catterall-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...</td>\n",
       "      <td>3</td>\n",
       "      <td>[mr., speaker, i, rise, on, a, point, of, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4305</td>\n",
       "      <td>173</td>\n",
       "      <td>70358</td>\n",
       "      <td>1</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>645329</td>\n",
       "      <td>388</td>\n",
       "      <td>2008-02-14 13:15:00-05</td>\n",
       "      <td>Routine Proceedings</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2008/2/14/tom-lukiwski-7/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['finally', ',', 'mr.', 'speaker', ',', 'i', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>[finally, mr., speaker, i, ask, that, all, rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1534</td>\n",
       "      <td>173</td>\n",
       "      <td>47007</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>2004-10-04</td>\n",
       "      <td>645329</td>\n",
       "      <td>388</td>\n",
       "      <td>2008-02-14 13:15:00-05</td>\n",
       "      <td>Routine Proceedings</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2008/2/14/tom-lukiwski-7/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['finally', ',', 'mr.', 'speaker', ',', 'i', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>[finally, mr., speaker, i, ask, that, all, rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1541</td>\n",
       "      <td>43</td>\n",
       "      <td>47014</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>2004-10-04</td>\n",
       "      <td>313253</td>\n",
       "      <td>1621</td>\n",
       "      <td>2004-02-06 10:05:00-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>/debates/2004/2/6/garry-breitkreuz-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'today', ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[mr., speaker, i, rise, today, on, a, question...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  politician_id  riding_id  party_id    end_date  start_date    id.1  \\\n",
       "0  2611           3465      35066         4  2005-11-29  1997-09-22  232373   \n",
       "1  3210           3465      70224         4  1997-04-27  1994-01-17  232373   \n",
       "2  4305            173      70358         1          \\N  2015-10-19  645329   \n",
       "3  1534            173      47007         1  2015-10-19  2004-10-04  645329   \n",
       "4  1541             43      47014         1  2015-10-19  2004-10-04  313253   \n",
       "\n",
       "   document_id                    time                h1_en  ...  \\\n",
       "0         1878  2001-05-03 13:50:00-04    Government Orders  ...   \n",
       "1         1878  2001-05-03 13:50:00-04    Government Orders  ...   \n",
       "2          388  2008-02-14 13:15:00-05  Routine Proceedings  ...   \n",
       "3          388  2008-02-14 13:15:00-05  Routine Proceedings  ...   \n",
       "4         1621  2004-02-06 10:05:00-05                  NaN  ...   \n",
       "\n",
       "                                 urlcache  h1_fr h2_fr h3_fr  who_fr  \\\n",
       "0  /debates/2001/5/3/marlene-catterall-1/    NaN   NaN   NaN     NaN   \n",
       "1  /debates/2001/5/3/marlene-catterall-1/    NaN   NaN   NaN     NaN   \n",
       "2      /debates/2008/2/14/tom-lukiwski-7/    NaN   NaN   NaN     NaN   \n",
       "3      /debates/2008/2/14/tom-lukiwski-7/    NaN   NaN   NaN     NaN   \n",
       "4   /debates/2004/2/6/garry-breitkreuz-1/    NaN   NaN   NaN     NaN   \n",
       "\n",
       "   who_context_fr  wordcount_en  \\\n",
       "0             NaN            \\N   \n",
       "1             NaN            \\N   \n",
       "2             NaN            \\N   \n",
       "3             NaN            \\N   \n",
       "4             NaN            \\N   \n",
       "\n",
       "                                   tokenized_content slug_length  \\\n",
       "0  ['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...           3   \n",
       "1  ['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...           3   \n",
       "2  ['finally', ',', 'mr.', 'speaker', ',', 'i', '...           3   \n",
       "3  ['finally', ',', 'mr.', 'speaker', ',', 'i', '...           3   \n",
       "4  ['mr.', 'speaker', ',', 'i', 'rise', 'today', ...           3   \n",
       "\n",
       "                                              tokens  \n",
       "0  [mr., speaker, i, rise, on, a, point, of, orde...  \n",
       "1  [mr., speaker, i, rise, on, a, point, of, orde...  \n",
       "2  [finally, mr., speaker, i, ask, that, all, rem...  \n",
       "3  [finally, mr., speaker, i, ask, that, all, rem...  \n",
       "4  [mr., speaker, i, rise, today, on, a, question...  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = list(set(df_concat.politician_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(politicians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict = vocab_count_dict.fromkeys(politicians, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at row 0\n",
      "at row 10000\n",
      "at row 20000\n",
      "at row 30000\n",
      "at row 40000\n",
      "at row 50000\n",
      "at row 60000\n",
      "at row 70000\n",
      "at row 80000\n",
      "at row 90000\n",
      "at row 100000\n",
      "at row 110000\n",
      "at row 120000\n",
      "at row 130000\n",
      "at row 140000\n",
      "at row 150000\n",
      "at row 160000\n",
      "at row 170000\n",
      "at row 180000\n",
      "at row 190000\n",
      "at row 200000\n",
      "at row 210000\n",
      "at row 220000\n",
      "at row 230000\n",
      "at row 240000\n",
      "at row 250000\n",
      "at row 260000\n",
      "at row 270000\n",
      "at row 280000\n",
      "at row 290000\n",
      "at row 300000\n",
      "at row 310000\n",
      "at row 320000\n",
      "at row 330000\n",
      "at row 340000\n",
      "at row 350000\n",
      "at row 360000\n",
      "at row 370000\n",
      "at row 380000\n",
      "at row 390000\n",
      "at row 400000\n",
      "at row 410000\n",
      "at row 420000\n",
      "at row 430000\n",
      "at row 440000\n",
      "at row 450000\n",
      "at row 460000\n",
      "at row 470000\n",
      "at row 480000\n",
      "at row 490000\n",
      "at row 500000\n",
      "at row 510000\n",
      "at row 520000\n",
      "at row 530000\n",
      "at row 540000\n",
      "at row 550000\n",
      "at row 560000\n",
      "at row 570000\n",
      "at row 580000\n",
      "at row 590000\n",
      "at row 600000\n",
      "at row 610000\n",
      "at row 620000\n",
      "at row 630000\n",
      "at row 640000\n",
      "at row 650000\n",
      "at row 660000\n",
      "at row 670000\n",
      "at row 680000\n",
      "at row 690000\n",
      "at row 700000\n",
      "at row 710000\n",
      "at row 720000\n",
      "at row 730000\n",
      "at row 740000\n",
      "at row 750000\n",
      "at row 760000\n",
      "at row 770000\n",
      "at row 780000\n",
      "at row 790000\n",
      "at row 800000\n",
      "at row 810000\n",
      "at row 820000\n",
      "at row 830000\n",
      "at row 840000\n",
      "at row 850000\n",
      "at row 860000\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = 0\n",
    "for index, row in df_concat.iterrows(): \n",
    "    if counter%100000 ==0:\n",
    "        print('at row', counter)\n",
    "        \n",
    "    pid = row['politician_id']\n",
    "    vocab_count_dict[pid].update(row['tokens'])\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict[3465].update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
