{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alecr\\Anaconda3\\envs\\gensim_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (20,23,28,29,30,31,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\data\\openparliament\\statements_nospeaker_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>politician_id</th>\n",
       "      <th>riding_id</th>\n",
       "      <th>party_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>start_date</th>\n",
       "      <th>id.1</th>\n",
       "      <th>document_id</th>\n",
       "      <th>time</th>\n",
       "      <th>h1_en</th>\n",
       "      <th>...</th>\n",
       "      <th>slug</th>\n",
       "      <th>urlcache</th>\n",
       "      <th>h1_fr</th>\n",
       "      <th>h2_fr</th>\n",
       "      <th>h3_fr</th>\n",
       "      <th>who_fr</th>\n",
       "      <th>who_context_fr</th>\n",
       "      <th>wordcount_en</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>slug_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2611</td>\n",
       "      <td>3465</td>\n",
       "      <td>35066</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-11-29</td>\n",
       "      <td>1997-09-22</td>\n",
       "      <td>232373</td>\n",
       "      <td>1878</td>\n",
       "      <td>2001-05-03 13:50:00-04</td>\n",
       "      <td>Government Orders</td>\n",
       "      <td>...</td>\n",
       "      <td>marlene-catterall-1</td>\n",
       "      <td>/debates/2001/5/3/marlene-catterall-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3210</td>\n",
       "      <td>3465</td>\n",
       "      <td>70224</td>\n",
       "      <td>4</td>\n",
       "      <td>1997-04-27</td>\n",
       "      <td>1994-01-17</td>\n",
       "      <td>232373</td>\n",
       "      <td>1878</td>\n",
       "      <td>2001-05-03 13:50:00-04</td>\n",
       "      <td>Government Orders</td>\n",
       "      <td>...</td>\n",
       "      <td>marlene-catterall-1</td>\n",
       "      <td>/debates/2001/5/3/marlene-catterall-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4305</td>\n",
       "      <td>173</td>\n",
       "      <td>70358</td>\n",
       "      <td>1</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>645329</td>\n",
       "      <td>388</td>\n",
       "      <td>2008-02-14 13:15:00-05</td>\n",
       "      <td>Routine Proceedings</td>\n",
       "      <td>...</td>\n",
       "      <td>tom-lukiwski-7</td>\n",
       "      <td>/debates/2008/2/14/tom-lukiwski-7/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['finally', ',', 'mr.', 'speaker', ',', 'i', '...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1534</td>\n",
       "      <td>173</td>\n",
       "      <td>47007</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>2004-10-04</td>\n",
       "      <td>645329</td>\n",
       "      <td>388</td>\n",
       "      <td>2008-02-14 13:15:00-05</td>\n",
       "      <td>Routine Proceedings</td>\n",
       "      <td>...</td>\n",
       "      <td>tom-lukiwski-7</td>\n",
       "      <td>/debates/2008/2/14/tom-lukiwski-7/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['finally', ',', 'mr.', 'speaker', ',', 'i', '...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1541</td>\n",
       "      <td>43</td>\n",
       "      <td>47014</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>2004-10-04</td>\n",
       "      <td>313253</td>\n",
       "      <td>1621</td>\n",
       "      <td>2004-02-06 10:05:00-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>garry-breitkreuz-1</td>\n",
       "      <td>/debates/2004/2/6/garry-breitkreuz-1/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>['mr.', 'speaker', ',', 'i', 'rise', 'today', ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  politician_id  riding_id  party_id    end_date  start_date    id.1  \\\n",
       "0  2611           3465      35066         4  2005-11-29  1997-09-22  232373   \n",
       "1  3210           3465      70224         4  1997-04-27  1994-01-17  232373   \n",
       "2  4305            173      70358         1          \\N  2015-10-19  645329   \n",
       "3  1534            173      47007         1  2015-10-19  2004-10-04  645329   \n",
       "4  1541             43      47014         1  2015-10-19  2004-10-04  313253   \n",
       "\n",
       "   document_id                    time                h1_en  ...  \\\n",
       "0         1878  2001-05-03 13:50:00-04    Government Orders  ...   \n",
       "1         1878  2001-05-03 13:50:00-04    Government Orders  ...   \n",
       "2          388  2008-02-14 13:15:00-05  Routine Proceedings  ...   \n",
       "3          388  2008-02-14 13:15:00-05  Routine Proceedings  ...   \n",
       "4         1621  2004-02-06 10:05:00-05                  NaN  ...   \n",
       "\n",
       "                  slug                                urlcache h1_fr h2_fr  \\\n",
       "0  marlene-catterall-1  /debates/2001/5/3/marlene-catterall-1/   NaN   NaN   \n",
       "1  marlene-catterall-1  /debates/2001/5/3/marlene-catterall-1/   NaN   NaN   \n",
       "2       tom-lukiwski-7      /debates/2008/2/14/tom-lukiwski-7/   NaN   NaN   \n",
       "3       tom-lukiwski-7      /debates/2008/2/14/tom-lukiwski-7/   NaN   NaN   \n",
       "4   garry-breitkreuz-1   /debates/2004/2/6/garry-breitkreuz-1/   NaN   NaN   \n",
       "\n",
       "   h3_fr  who_fr  who_context_fr wordcount_en  \\\n",
       "0    NaN     NaN             NaN           \\N   \n",
       "1    NaN     NaN             NaN           \\N   \n",
       "2    NaN     NaN             NaN           \\N   \n",
       "3    NaN     NaN             NaN           \\N   \n",
       "4    NaN     NaN             NaN           \\N   \n",
       "\n",
       "                                   tokenized_content slug_length  \n",
       "0  ['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...           3  \n",
       "1  ['mr.', 'speaker', ',', 'i', 'rise', 'on', 'a'...           3  \n",
       "2  ['finally', ',', 'mr.', 'speaker', ',', 'i', '...           3  \n",
       "3  ['finally', ',', 'mr.', 'speaker', ',', 'i', '...           3  \n",
       "4  ['mr.', 'speaker', ',', 'i', 'rise', 'today', ...           3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '!\"#$%&()*+,-./:;<=>@[]^_`{|}~' + \"''\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pun_trans = str.maketrans(dict.fromkeys(punctuation, ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "df_chunk = pd.read_csv(r\"D:\\data\\openparliament\\statements_nospeaker_en.csv\", chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_en_list = []  # append the content from each chunk df here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_column (row):\n",
    "    soup = BeautifulSoup(row)\n",
    "    text = soup.text.lower()\n",
    "    text = text.translate(pun_trans)\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    text = text.replace('—', ' ')\n",
    "    words = word_tokenize(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word_tokens):\n",
    "    tokens = [w for w in word_tokens if not w in stop_words]\n",
    "    tokens = [t for t in tokens if not t.isdigit()]\n",
    "    words = [ps.stem(w) for w in tokens]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Each chunk is in df format\n",
    "count = 0\n",
    "for chunk in df_chunk:  \n",
    "    # perform data filtering \n",
    "    print('chunk count', count)\n",
    "    count+=1\n",
    "    chunk_filter = chunk.drop(['Unnamed: 0'], axis=1)\n",
    "    content_en = chunk.content_en\n",
    "    #print(type(content_en))\n",
    "    content_en = content_en.apply(tokenize_column)\n",
    "    content_en = content_en.apply(remove_stopwords)\n",
    "    chunk_filter['tokens'] = content_en\n",
    "    #print(type(chunk_filter))\n",
    "    #print('done')\n",
    "    # Once the data filtering is done, append the chunk to list\n",
    "    content_en_list.append(chunk_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'politician_id', 'riding_id', 'party_id', 'end_date',\n",
       "       'start_date', 'id.1', 'document_id', 'time', 'h1_en', 'h2_en',\n",
       "       'member_id', 'who_en', 'content_en', 'sequence_en', 'wordcount',\n",
       "       'politician_id.1', 'procedural', 'h3_en', 'who_hocid', 'content_fr',\n",
       "       'statement_type', 'written_question', 'source_id', 'who_context_en',\n",
       "       'slug', 'urlcache', 'h1_fr', 'h2_fr', 'h3_fr', 'who_fr',\n",
       "       'who_context_fr', 'wordcount_en', 'tokenized_content', 'slug_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vocab_count_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = list(set(df.politician_id))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vocab_count_dict = vocab_count_dict.fromkeys(politicians, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(k,v_list):\n",
    "    if k in vocab_count_dict:\n",
    "        for v in v_list:\n",
    "            vocab_count_dict[k].add(v)\n",
    "    else:\n",
    "        for v in v_list:\n",
    "            vocab_count_dict[k] = {v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "updating id 3465 ['mr', 'speaker', 'rise', 'point', 'order', 'believ', 'would', 'find', 'unanim', 'consent']\n",
      "10000\n",
      "updating id 415 ['mr', 'speaker', 'ever', 'sinc', 'prime', 'minist', 'fled', 'davo', 'switzerland', 'announc']\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_tokens = 0\n",
    "count = 0\n",
    "\n",
    "for index, row in df.iterrows(): \n",
    "    soup = BeautifulSoup(row.content_en)\n",
    "    text = soup.text.lower()\n",
    "    text = text.translate(pun_trans)\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    text = text.replace('—', ' ')\n",
    "    word_tokens = word_tokenize(text)\n",
    "    tokens = [w for w in word_tokens if not w in stop_words]\n",
    "    tokens = [t for t in tokens if not t.isdigit()]\n",
    "    words = [ps.stem(w) for w in tokens]\n",
    "    \n",
    "    pid = row['politician_id']\n",
    "    add(pid,words)\n",
    "    \n",
    "    if len(words)>max_tokens:\n",
    "        max_tokens = len(words)\n",
    "    if count%10000==0:\n",
    "        print(count)\n",
    "        print('updating id', row['politician_id'], words[:10])\n",
    "    \n",
    "    \n",
    "    count+=1\n",
    "#print(row.who_en, \"gave the longest speech at\", max_tokens, 'words')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'?',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'associ',\n",
       " 'believ',\n",
       " 'bloc',\n",
       " 'candid',\n",
       " 'committe',\n",
       " 'debt',\n",
       " 'du',\n",
       " 'far',\n",
       " 'first',\n",
       " 'gave',\n",
       " 'gross',\n",
       " 'hard',\n",
       " 'hous',\n",
       " 'islet',\n",
       " 'issu',\n",
       " 'kamouraska',\n",
       " 'key',\n",
       " 'l',\n",
       " 'liber',\n",
       " 'like',\n",
       " 'local',\n",
       " 'long',\n",
       " 'lot',\n",
       " 'loup',\n",
       " 'make',\n",
       " 'member',\n",
       " 'montmagni',\n",
       " 'motion',\n",
       " 'mr',\n",
       " 'oblig',\n",
       " 'parti',\n",
       " 'quebec',\n",
       " 'question',\n",
       " 'respect',\n",
       " 'respons',\n",
       " 'rivièr',\n",
       " 'sens',\n",
       " 'separ',\n",
       " 'side',\n",
       " 'speaker',\n",
       " 'summer',\n",
       " 'tell',\n",
       " 'thank',\n",
       " 'warm',\n",
       " 'welcom',\n",
       " 'work',\n",
       " 'would',\n",
       " 'île'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_count_dict[443]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'?',\n",
       " 'absurd',\n",
       " 'actual',\n",
       " 'add',\n",
       " 'addit',\n",
       " 'agreement',\n",
       " 'altogeth',\n",
       " 'american',\n",
       " 'argument',\n",
       " 'around',\n",
       " 'aspect',\n",
       " 'badli',\n",
       " 'ban',\n",
       " 'bean',\n",
       " 'beanstalk',\n",
       " 'becom',\n",
       " 'behalf',\n",
       " 'believ',\n",
       " 'big',\n",
       " 'breath',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'caucu',\n",
       " 'cautionari',\n",
       " 'centr',\n",
       " 'chapter',\n",
       " 'children',\n",
       " 'cite',\n",
       " 'claus',\n",
       " 'clear',\n",
       " 'colleagu',\n",
       " 'commod',\n",
       " 'compromis',\n",
       " 'corpor',\n",
       " 'could',\n",
       " 'countri',\n",
       " 'coupl',\n",
       " 'cow',\n",
       " 'deal',\n",
       " 'deliber',\n",
       " 'democrat',\n",
       " 'deni',\n",
       " 'disservic',\n",
       " 'done',\n",
       " 'econom',\n",
       " 'either',\n",
       " 'eloqu',\n",
       " 'enter',\n",
       " 'essenti',\n",
       " 'even',\n",
       " 'eventu',\n",
       " 'exactli',\n",
       " 'exampl',\n",
       " 'expand',\n",
       " 'fair',\n",
       " 'famili',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'find',\n",
       " 'fit',\n",
       " 'foreign',\n",
       " 'forward',\n",
       " 'free',\n",
       " 'freer',\n",
       " 'fresh',\n",
       " 'fta',\n",
       " 'fundament',\n",
       " 'gall',\n",
       " 'gasolin',\n",
       " 'gave',\n",
       " 'get',\n",
       " 'give',\n",
       " 'glare',\n",
       " 'go',\n",
       " 'halifax',\n",
       " 'happi',\n",
       " 'healthi',\n",
       " 'hon',\n",
       " 'hous',\n",
       " 'industri',\n",
       " 'interest',\n",
       " 'interf',\n",
       " 'issu',\n",
       " 'jack',\n",
       " 'jeopard',\n",
       " 'joliett',\n",
       " 'leav',\n",
       " 'left',\n",
       " 'like',\n",
       " 'lose',\n",
       " 'lost',\n",
       " 'made',\n",
       " 'make',\n",
       " 'manufactur',\n",
       " 'market',\n",
       " 'marketplac',\n",
       " 'member',\n",
       " 'mini',\n",
       " 'minut',\n",
       " 'mmt',\n",
       " 'motion',\n",
       " 'mr',\n",
       " 'nafta',\n",
       " 'nation',\n",
       " 'natur',\n",
       " 'negoti',\n",
       " 'never',\n",
       " 'new',\n",
       " 'none',\n",
       " 'north',\n",
       " 'note',\n",
       " 'omiss',\n",
       " 'one',\n",
       " 'opportun',\n",
       " 'oppos',\n",
       " 'paid',\n",
       " 'parti',\n",
       " 'partner',\n",
       " 'peopl',\n",
       " 'point',\n",
       " 'posit',\n",
       " 'predict',\n",
       " 'principl',\n",
       " 'protect',\n",
       " 'put',\n",
       " 'right',\n",
       " 'said',\n",
       " 'saw',\n",
       " 'sell',\n",
       " 'sens',\n",
       " 'sent',\n",
       " 'settl',\n",
       " 'situat',\n",
       " 'smart',\n",
       " 'someth',\n",
       " 'soon',\n",
       " 'sovereignti',\n",
       " 'speaker',\n",
       " 'sprout',\n",
       " 'state',\n",
       " 'statu',\n",
       " 'step',\n",
       " 'su',\n",
       " 'sue',\n",
       " 'support',\n",
       " 'surrend',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'thing',\n",
       " 'three',\n",
       " 'today',\n",
       " 'trade',\n",
       " 'type',\n",
       " 'urg',\n",
       " 'us',\n",
       " 'use',\n",
       " 'vulner',\n",
       " 'water',\n",
       " 'whole',\n",
       " 'winnipeg',\n",
       " 'word',\n",
       " 'world',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'zeal'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_count_dict[185]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(politicians)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "counter = 0\n",
    "for index, row in df_concat.iterrows(): \n",
    "    if counter%100000 ==0:\n",
    "        print('at row', counter)\n",
    "        \n",
    "    pid = row['politician_id']\n",
    "    vocab_count_dict[pid].update(row['tokens'])\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4156"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politicians[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict[4156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84078"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_count_dict[4156])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set = vocab_count_dict[4156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(p_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set.remove('sacrifice.\\\\ntoday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_vocab = 0\n",
    "vocab_politician = None\n",
    "for key, p_set in vocab_count_dict.items():\n",
    "    print(key, \": \", len(list(p_set)))\n",
    "    if len(list(p_set))>max_vocab:\n",
    "        max_vocab = len(list(p_set))\n",
    "        vocab_politician = key\n",
    "\n",
    "print(vocab_politician, 'has the biggest vocabulary at', max_vocab, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(vocab_count_dict.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tasks: add 'mr' to stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
