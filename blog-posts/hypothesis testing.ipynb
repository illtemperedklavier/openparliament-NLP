{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be item 2 in what will be a series of posts on mining information from a psql dump of openparliament.ca. This post will be about hypothesis testing, as we can test some of the assumptions that people tend to make about language in politics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.lingo-ninja.com/RepsVsDems [#TODO hyperlink that] This article purports to refute the idea that in the US, democrats tend to have a larger vocabulary, with an analysis of words tweeted. In my earlier post, I commented on their methodological choices, and explained how in contrast, for my analysis, I use the pre-trained SpaCy POS tagger to remove named entities, stopwords, punctuation, and then save the lemmas to a Counter object, in order to not overcount different tenses of the same word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, in want of actual analysis, I decided this should be a post about hypothesis testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h0 = Liberals and Conservatives* have the same vocabulary size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There have been many iterations, fractures, and mergers of the Conservative party, but they consist of the same people, so here, the Conservative Party of Canada, Progressive Conservatives, Canadian Alliance, Reform Party of Canada, and the Canadian Reform Alliance Party (that name didn't last long) shall be treated as just one party for the sake of analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>politician_id</th>\n",
       "      <th>riding_id</th>\n",
       "      <th>party_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>start_date</th>\n",
       "      <th>member_id</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>token_count</th>\n",
       "      <th>log_words</th>\n",
       "      <th>scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2693</td>\n",
       "      <td>70159</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-09-11</td>\n",
       "      <td>2000-04-02</td>\n",
       "      <td>2693</td>\n",
       "      <td>3340</td>\n",
       "      <td>161660</td>\n",
       "      <td>11.993251</td>\n",
       "      <td>278.489969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2693</td>\n",
       "      <td>70159</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-01-28</td>\n",
       "      <td>2000-09-12</td>\n",
       "      <td>2693</td>\n",
       "      <td>3340</td>\n",
       "      <td>161660</td>\n",
       "      <td>11.993251</td>\n",
       "      <td>278.489969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2693</td>\n",
       "      <td>70159</td>\n",
       "      <td>26</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>1997-09-22</td>\n",
       "      <td>2693</td>\n",
       "      <td>3340</td>\n",
       "      <td>161660</td>\n",
       "      <td>11.993251</td>\n",
       "      <td>278.489969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2693</td>\n",
       "      <td>24016</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-05-23</td>\n",
       "      <td>2001-01-29</td>\n",
       "      <td>2693</td>\n",
       "      <td>3340</td>\n",
       "      <td>161660</td>\n",
       "      <td>11.993251</td>\n",
       "      <td>278.489969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4136</td>\n",
       "      <td>59023</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-05-23</td>\n",
       "      <td>2002-01-28</td>\n",
       "      <td>4136</td>\n",
       "      <td>2545</td>\n",
       "      <td>53121</td>\n",
       "      <td>10.880328</td>\n",
       "      <td>233.908398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   politician_id  riding_id  party_id    end_date  start_date  member_id  \\\n",
       "0           2693      70159         5  2000-09-11  2000-04-02       2693   \n",
       "1           2693      70159         4  2001-01-28  2000-09-12       2693   \n",
       "2           2693      70159        26  2000-04-01  1997-09-22       2693   \n",
       "3           2693      24016         4  2004-05-23  2001-01-29       2693   \n",
       "4           4136      59023         4  2005-05-23  2002-01-28       4136   \n",
       "\n",
       "   vocab_size  token_count  log_words      scaled  \n",
       "0        3340       161660  11.993251  278.489969  \n",
       "1        3340       161660  11.993251  278.489969  \n",
       "2        3340       161660  11.993251  278.489969  \n",
       "3        3340       161660  11.993251  278.489969  \n",
       "4        2545        53121  10.880328  233.908398  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_vocab = pd.read_csv(r\"D:\\data\\openparliament\\politician_vocab.csv\",index_col='Unnamed: 0')\n",
    "pol_vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It wouldn't be fair to compare the vocab sizes without context for how many words they've spoken, so I'm going to count the total tokens spoken per mp."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.read_csv(r\"D:\\data\\openparliament\\text_en.csv\",index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['tokens'] = df.tokens.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['token_count'] = df.tokens.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "words_spoken = df.pivot_table(index='politician_id', values='token_count', aggfunc=sum)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "words_spoken.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "words_spoken.token_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see here, there are six orders of magnitude between the most and least locquacious members. For this, I'm going to scale the sum of tokens spoken with a natural log."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "words_spoken['log_words'] = words_spoken.token_count.apply(np.log)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "words_spoken.log_words.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pol_vocab = pol_vocab.merge(words_spoken,how='inner',left_on='politician_id',right_on='politician_id')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pol_vocab.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pol_vocab['scaled'] = pol_vocab['vocab_size']/pol_vocab['log_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1499.000000\n",
       "mean      339.769742\n",
       "std       150.701900\n",
       "min         0.227560\n",
       "25%       229.792183\n",
       "50%       337.468426\n",
       "75%       441.582375\n",
       "max       856.785195\n",
       "Name: scaled, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_vocab.scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this bit of consolidation partially happened elsewhere, and I can imagine Quebec people, Green Party,NDP,and various flavours of piqued historical conservative party voters protesting in rage that they can't be divided so casually into liberal, conservative, and quebec. Well, this is for the sake of a hypothesis testing demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_dict = {1:'con',2:'lib',4:'lib',10: 'con', 3:'quebec', 28:'con', 25:'con', 5:'ind',26:'con', 46:'quebec',9:'lib', 39:'quebec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_vocab['party'] = pol_vocab.party_id.replace(party_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Null Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do here, in this example, is to decide upon a null hypothesis. That's what you would assume to be true in the simplest version of reality. In this case, I'll assume that since the people who work in the offices of MPs and prepare their speeches are by and large educated in the same places, they more or less write the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H0**: VOCAB^conservatives = VOCAB^liberals\n",
    "\n",
    "**H1**: Vocab^conservatives != VOCAB^liberals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_means = pol_vocab.groupby('party').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party\n",
       "con       4544.067290\n",
       "ind       3900.815789\n",
       "lib       3661.321965\n",
       "quebec    3641.533679\n",
       "Name: vocab_size, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_means['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_stds = pol_vocab.groupby('party').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party\n",
       "con       2085.117271\n",
       "ind       1901.188787\n",
       "lib       2136.081279\n",
       "quebec    1979.218785\n",
       "Name: vocab_size, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_stds['vocab_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of hypothesis testing is to test whether these two means come from the same distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the significance value always has to be decided upon ahead of time, I'm going to choose 0.05 as the P value, as that's the most common value used in experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_vocab = pol_vocab[pol_vocab.party == 'con']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal_vocab = pol_vocab[pol_vocab.party == 'lib']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = ttest_ind(conservative_vocab,liberal_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ttest_ind function from scipy gives you the t-score and the p-value. In this case, since we've decided that if p <= 0.05, that is sufficient evidence to reject the null hypothesis, now it's time to see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.783301607367376e-13"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in scientific notation, so the p value is ~3.8^-13, which is a *very* small number. This is sufficient to reject the null hypothesis, that conservatives and liberals have similar vocabulary sizes. An alternate hypothesis must be true. While you can't reject the null hypothesis and then claim that whatever alternate hypothesis you have *must* be true, something else must true. Tied to reality as we are, going back to the mean values earlier, the mean adjusted vocabulary size for conservative speeches is 2085, in contrast to 2136 for the liberals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary caveat here is that the specific numbers don't mean much here at all - so long as they were arrived at in the same way for all groups. The vocab sizes are adjusted by dividing by the log of total words spoken, and stopwords and proper names were removed from the words in the original vocab size count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
